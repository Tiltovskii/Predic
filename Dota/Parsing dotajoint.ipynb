{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d4726797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import aiohttp\n",
    "import asyncio\n",
    "from fake_useragent import UserAgent\n",
    "import re\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "acd22e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'name_team_1': {},\n",
    "        'rank_team_1': {},\n",
    "        'ratio_team_1': {},\n",
    "        'points_team_1':{},\n",
    "        'prize_team_1': {},\n",
    "        'players_team_1': {},\n",
    "        'heroes_team_1':{},\n",
    "        'name_team_2': {},\n",
    "        'rank_team_2': {},\n",
    "        'ratio_team_2': {},\n",
    "        'points_team_2': {},\n",
    "        'prize_team_2': {},\n",
    "        'players_team_2':{},\n",
    "        'heroes_team_2': {},\n",
    "        'won_team_1': {},\n",
    "        'data': {}\n",
    "                   }\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ca49ea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_match(url, session):\n",
    "    global df\n",
    "    try:\n",
    "        headers = {\n",
    "            'user-agent': UserAgent()['google_chrome']\n",
    "        }\n",
    "\n",
    "        async with session.get(url=url, headers=headers) as response:\n",
    "            response_text = await response.text()\n",
    "            soup = bs(response_text, 'lxml')\n",
    "            matches = soup.find_all('section', class_=lambda x: ('boxed-section' in x.split())&('antispoiler-hide' in x.split()))\n",
    "\n",
    "            teams = soup.find_all('div', class_='widget-team')\n",
    "            teams_info = {}\n",
    "\n",
    "            for i, team in enumerate(teams, start=1):\n",
    "                team_name = team.find('div', class_='txt-content').text\n",
    "                infos = team.find('ul', class_='widget-icon-info').find_all('li')\n",
    "                rank =  infos[0].text.split(':')[1].strip('.')\n",
    "                ratio = re.findall(r'\\((.+?)\\)', infos[1].text)[0].strip('%')\n",
    "                points = re.sub(',', '', infos[2].text.split(':')[1])\n",
    "                prize = re.sub(',', '', re.findall(r'\\:(.+?)\\â‚¬', infos[3].text)[0])\n",
    "\n",
    "                rank = 0 if (rank == '-') or (rank == '---') else rank\n",
    "                \n",
    "                points = 0 if points == '---' else points\n",
    "\n",
    "                teams_info[f'team_name_{i}'] = team_name\n",
    "                teams_info[f'rank_{i}'] = rank\n",
    "                teams_info[f'ratio_{i}'] = ratio\n",
    "                teams_info[f'points_{i}'] = points\n",
    "                teams_info[f'prize_{i}'] = prize\n",
    "\n",
    "            for match in matches:\n",
    "                who_won = match.find_all('div', class_='content-match-sub-team-titles')\n",
    "\n",
    "                if who_won[0].find('i', class_='icon-winner'): won_left = 1\n",
    "                else: won_left = 0\n",
    "                \n",
    "                time = soup.find('span', class_='tztime').get('data-time')\n",
    "                team_picks = match.find_all('ul', class_='content-match-sub-picks')\n",
    "                players = []\n",
    "                heroes = []\n",
    "\n",
    "                for team_pick in team_picks:\n",
    "                    picks = team_pick.find_all('li')\n",
    "\n",
    "                    for i, pick in enumerate(picks):\n",
    "                        heroes += [pick.find('img').get('title')]\n",
    "                        players += [pick.find('span').text]\n",
    "\n",
    "                df = df.append({'name_team_1': teams_info['team_name_1'],\n",
    "                                'rank_team_1': teams_info['rank_1'],\n",
    "                                'ratio_team_1': teams_info['ratio_1'],\n",
    "                                'points_team_1': teams_info['points_1'],\n",
    "                                'prize_team_1': teams_info['prize_1'],\n",
    "                                'players_team_1':players[:5],\n",
    "                                'heroes_team_1':heroes[:5],\n",
    "                                'name_team_2': teams_info['team_name_2'],\n",
    "                                'rank_team_2': teams_info['rank_2'],\n",
    "                                'ratio_team_2': teams_info['ratio_2'],\n",
    "                                'points_team_2': teams_info['points_2'],\n",
    "                                'prize_team_2': teams_info['prize_2'],\n",
    "                                'players_team_2':players[5:],\n",
    "                                'heroes_team_2':heroes[5:],\n",
    "                                'won_team_1': won_left,\n",
    "                                'data': datetime.utcfromtimestamp(int(time)).strftime('%Y-%m-%d')\n",
    "                               }, ignore_index=True)\n",
    "\n",
    "        \n",
    "    except Exception as exc:\n",
    "        print('exc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4e80dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_finished_matches(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        response = await session.get(url=url, headers = headers)\n",
    "        j = await response.json()\n",
    "        soup =  bs(j['data'], \"html.parser\")\n",
    "        matches = soup.find_all('tr', class_='finished')\n",
    "        tasks = []\n",
    "        for match in matches:\n",
    "            link = match.find('a', class_='table-cell-container').get('href')\n",
    "            await parse_match(link, session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dc04a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack_of_urls = [[f'https://www.joindota.com/ajax/list_load?name=matches_finished&page={i}&a1=&devmode=1&language=en'\n",
    "        for i in range(20*j + 1, 20*(j+1) + 1) ] for j in range(50)]\n",
    "\n",
    "headers = {\n",
    "        'user-agent': UserAgent()['google_chrome']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a77cc9ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e36c0742434a718185c89711744b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for urls in tqdm(pack_of_urls):\n",
    "    tasks = []\n",
    "    for url in urls:\n",
    "        task = parse_finished_matches(url)\n",
    "        tasks.append(task)\n",
    "    await asyncio.gather(*tasks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c2b32dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['heroes_team_1'].apply(lambda x: x == [])].index)\n",
    "df = df.drop(df[df['heroes_team_1'].apply(lambda x: x[0] == '')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8a398c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank_team_1'] = df['rank_team_1'].apply(lambda x: 0 if x == '---' else x)\n",
    "df['rank_team_2'] = df['rank_team_2'].apply(lambda x: 0 if x == '---' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5dc82f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank_team_1'] = df['rank_team_1'].astype(int)\n",
    "df['rank_team_2'] = df['rank_team_2'].astype(int)\n",
    "\n",
    "df['points_team_1'] = df['points_team_1'].astype(int)\n",
    "df['points_team_2'] = df['points_team_2'].astype(int)\n",
    "\n",
    "df['ratio_team_1'] = df['ratio_team_1'].astype(int)\n",
    "df['ratio_team_2'] = df['ratio_team_2'].astype(int)\n",
    "\n",
    "df['prize_team_1'] = df['prize_team_1'].astype(int)\n",
    "df['prize_team_2'] = df['prize_team_2'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adeea549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dota_matches_1k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3e04f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
